{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('./TutorialVQAData/videos.json','r'))\n",
    "train = json.load(open('./TutorialVQAData/train.json','r'))\n",
    "test = json.load(open('./TutorialVQAData/test.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for i in range(len(data)):\n",
    "    df[data[i]['video_id']] = data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, text):\n",
    "\n",
    "    inputs = tokenizer(question, text, return_tensors='pt')\n",
    "    #start_positions = torch.tensor([3])\n",
    "    #end_positions = torch.tensor([7])\n",
    "    #outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n",
    "    outputs = model(**inputs)\n",
    "    loss = outputs.loss\n",
    "    print(loss)\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    tokens = inputs['input_ids'][0][torch.argmax(start_scores): torch.argmax(end_scores) + 1]\n",
    "    answerTokens = tokenizer.convert_ids_to_tokens(tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return torch.argmax(start_scores)-len(tokenizer(question)['input_ids']), torch.argmax(end_scores)+1 -len(tokenizer(question)['input_ids']), tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])), tokenizer.convert_tokens_to_string(answerTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(3) tensor(6) [CLS] what is jim henson ? [SEP] jim henson was a nice puppet . john smith was a banker . [SEP] a nice puppet\n"
     ]
    }
   ],
   "source": [
    "question, text = \"what is jim henson?\", \"Jim Henson was a nice puppet. John Smith was a banker.\"\n",
    "start, end, answerTokens, answer = get_answer(question, text)\n",
    "print(start, end, answerTokens, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single(question_df, context):\n",
    "    context = ' '.join(context['transcript'])\n",
    "    question = question_df['question']\n",
    "    start_true = question_df['answer_start']\n",
    "    end_true = question_df['answer_end']\n",
    "    \n",
    "    start, end, answerTokens, answer = get_answer(question, context[:512])\n",
    "    \n",
    "    print('question: ', question)\n",
    "    print('answer: ', answer)\n",
    "    \n",
    "    return start_true-start, end_true-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "question:  how do i create a new action?\n",
      "answer:  \n",
      "(tensor(-111), tensor(-103))\n",
      "None\n",
      "question:  how do i change the text color of an image?\n",
      "answer:  i want to create beautiful type\n",
      "(tensor(5), tensor(3))\n",
      "None\n",
      "question:  what do you have to do to get a new layer?\n",
      "answer:  take a look at this layers panel\n",
      "(tensor(-70), tensor(-72))\n",
      "None\n",
      "question:  how to align objects to layers.\n",
      "answer:  \n",
      "(tensor(46), tensor(55))\n",
      "None\n",
      "question:  3\n",
      "answer:  tutorial page or photos of your own\n",
      "(tensor(-44), tensor(-51))\n",
      "None\n",
      "question:  why isn't quick select actually selecting the selected bit?\n",
      "answer:  it actually selects too much , and it ends up selecting the entire document because there aren ' t very many tonal or color values between the green and the blue\n",
      "(tensor(-76), tensor(-106))\n",
      "None\n",
      "question:  how can i keep cropped pixels?\n",
      "answer:  by selecting the crop tool here in the tools panel\n",
      "(tensor(-61), tensor(-64))\n",
      "None\n",
      "question:  how do i save my project?\n",
      "answer:  you can use the sample images available for download on the tutorial page or photos of your own\n",
      "(tensor(1), tensor(-16))\n",
      "None\n",
      "question:  tell me, how do i change the color of a vector image?\n",
      "answer:  linking smart objects . that was a test\n",
      "(tensor(48), tensor(59))\n",
      "None\n",
      "question:  how do i put the background layer above all the other layers?\n",
      "answer:  the layers panel\n",
      "(tensor(22), tensor(22))\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(test_single(test[i], df[test[i]['video_id']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'small_train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c7d276a8d76d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m trainer = Trainer(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmall_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmall_eval_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'small_train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test_trainer\")\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
